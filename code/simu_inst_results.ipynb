{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be3efe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "from src.data.data_load import (\n",
    "    load_tables, \n",
    "    load_online_instance, \n",
    "    load_distances, \n",
    "    upload_ONLINE_static_solution\n",
    ")\n",
    "from src.data.solution_load import load_solution_dfs, _include_all_city\n",
    "from src.utils.filtering import flexible_filter\n",
    "from src.utils.plotting import plot_metrics_comparison_dynamic\n",
    "from src.data.metrics import collect_results_to_df, compute_metrics_with_moves, get_day_plotting_df\n",
    "from src.config.experimentation_config import *\n",
    "from src.config.SD_experimentation_config import *\n",
    "from src.config.config import *\n",
    "\n",
    "data_path = '../data'\n",
    "\n",
    "distance_type = 'osrm'              # Options: ['osrm', 'manhattan']\n",
    "dist_method = 'haversine'      # Options: ['precalced', 'haversine']\n",
    "\n",
    "optimization_obj = 'driver_distance'\n",
    "\n",
    "directorio_df, labors_raw_df, cities_df, duraciones_df, valid_cities = load_tables(data_path, generate_labors=False)\n",
    "# dist_dict = load_distances(data_path, distance_type, instance, dist_method)\n",
    "\n",
    "metricas = ['service_count', 'vt_count', 'num_drivers', 'driver_extra_time', 'driver_move_distance']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2dbb65",
   "metadata": {},
   "source": [
    "\n",
    "# Upload results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5979bebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "inst_path = f\"{data_path}/resultados/online_operation/instAD3/haversine\"\n",
    "labors_algo_df = pd.DataFrame()\n",
    "moves_algo_df = pd.DataFrame()\n",
    "\n",
    "upload_path = f\"{inst_path}/res_algo_ONLINE_static.pkl\"\n",
    "\n",
    "\n",
    "with open(upload_path, \"rb\") as f:\n",
    "    res = pickle.load(f)\n",
    "    results_df, moves_df, postponed_labors = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5d8d72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_simulated_instances():\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    for n_serv in n_services:\n",
    "        labors_real_dfs = pd.DataFrame()\n",
    "        labors_static_dfs = pd.DataFrame()\n",
    "        labors_dynamic_dfs = pd.DataFrame()\n",
    "        for scenario in scenarios:\n",
    "            for seed in seeds:\n",
    "                instance = f'N{n_serv}/{scenario}/seed_{seed}'\n",
    "                labors_real_df, labors_static_df, labors_dynamic_df = load_online_instance(data_path, instance, labors_raw_df)\n",
    "\n",
    "                for df in [labors_real_df, labors_static_df, labors_dynamic_df]:\n",
    "                    df['n_serv'] = n_serv\n",
    "                    df['scenario'] = scenario\n",
    "                    df['seed'] = seed\n",
    "                \n",
    "                labors_real_df = _include_all_city(labors_real_df)\n",
    "                labors_static_df = _include_all_city(labors_static_df)\n",
    "                labors_dynamic_df = _include_all_city(labors_dynamic_df)\n",
    "\n",
    "                labors_real_dfs = pd.concat([labors_real_dfs, labors_real_df])\n",
    "                labors_static_dfs = pd.concat([labors_static_dfs, labors_static_df])\n",
    "                labors_dynamic_dfs = pd.concat([labors_dynamic_dfs, labors_dynamic_df])\n",
    "        \n",
    "        results[n_serv] = (labors_real_dfs, labors_static_dfs, labors_dynamic_dfs)\n",
    "\n",
    "    return results\n",
    "        \n",
    "results = upload_simulated_instances()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f4962a",
   "metadata": {},
   "source": [
    "# Instance exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0100896",
   "metadata": {},
   "source": [
    "## Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93c8e59f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9ee5988d8143bd8513b03f976215e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='N services', options=(900, 950, 1000, 1050, 1100, 1150, 1200), val…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from ipywidgets import interact, Dropdown\n",
    "\n",
    "\n",
    "def plot_topology_reactive(results, n_services_list, scenarios, seeds):\n",
    "    \"\"\"\n",
    "    Creates two reactive dropdowns: n_services and city.\n",
    "    Whenever the user selects a new value, the plots update.\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- helper: available cities for a given n_services ----\n",
    "    def available_cities(n):\n",
    "        df_real = results[n][0]\n",
    "        if \"city\" in df_real.columns:\n",
    "            return sorted(df_real[\"city\"].dropna().unique())\n",
    "        return []\n",
    "\n",
    "    # ---- reactive plotting function ----\n",
    "    def draw(n_services, city):\n",
    "        df_real, df_static, df_dynamic = results[n_services]\n",
    "\n",
    "        # ---------------- FILTER BY CITY ----------------\n",
    "        dfR = df_real[df_real['city'] == city].copy()\n",
    "        dfS = df_static[df_static['city'] == city].copy()\n",
    "        dfD = df_dynamic[df_dynamic['city'] == city].copy()\n",
    "\n",
    "        # ---------------- HISTOGRAM DATA ----------------\n",
    "        hist_rows = []\n",
    "        for sc in scenarios:\n",
    "            sub = dfR[dfR[\"scenario\"] == sc]\n",
    "            for seed, g in sub.groupby(\"seed\"):\n",
    "                vt_count = int((g[\"labor_category\"] == \"VEHICLE_TRANSPORTATION\").sum())\n",
    "                hist_rows.append({\"scenario\": sc, \"seed\": seed, \"vt\": vt_count})\n",
    "\n",
    "        hist_df = pd.DataFrame(hist_rows)\n",
    "\n",
    "        # ---------------- BOX PLOT DATA ----------------\n",
    "        box_rows = []\n",
    "        for sc in scenarios:\n",
    "            df_stat_sc = dfS[dfS[\"scenario\"] == sc]\n",
    "            df_dyn_sc = dfD[dfD[\"scenario\"] == sc]\n",
    "\n",
    "            stat_by_seed = df_stat_sc.groupby(\"seed\")[\"service_id\"].nunique()\n",
    "            dyn_by_seed = df_dyn_sc.groupby(\"seed\")[\"service_id\"].nunique()\n",
    "\n",
    "            union_seeds = sorted(set(stat_by_seed.index) | set(dyn_by_seed.index))\n",
    "            for seed in union_seeds:\n",
    "                n_static = int(stat_by_seed.get(seed, 0))\n",
    "                n_dynamic = int(dyn_by_seed.get(seed, 0))\n",
    "                total = n_static + n_dynamic\n",
    "                prop_static = (n_static / total) if total > 0 else np.nan\n",
    "                box_rows.append({\n",
    "                    \"scenario\": sc,\n",
    "                    \"seed\": seed,\n",
    "                    \"prop_static\": prop_static\n",
    "                })\n",
    "\n",
    "        box_df = pd.DataFrame(box_rows)\n",
    "\n",
    "        # ---------------- PLOTTING ----------------\n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=3,\n",
    "            subplot_titles=[f\"VT counts: {sc}\" for sc in scenarios] +\n",
    "                           [\"Static proportion per scenario\"],\n",
    "            specs=[[{\"type\": \"xy\"}]*3,\n",
    "                   [{\"colspan\": 3, \"type\": \"xy\"}, None, None]],\n",
    "            vertical_spacing=0.15\n",
    "        )\n",
    "\n",
    "        # -- top row histograms --\n",
    "        bins = 20\n",
    "        for i, sc in enumerate(scenarios):\n",
    "            h = hist_df[hist_df.scenario == sc]\n",
    "            if not h.empty:\n",
    "                vals, edges = np.histogram(h[\"vt\"].values, bins=bins)\n",
    "                centers = (edges[:-1] + edges[1:]) / 2\n",
    "                fig.add_trace(\n",
    "                    go.Bar(x=centers, y=vals, showlegend=False),\n",
    "                    row=1, col=i+1\n",
    "                )\n",
    "            fig.update_xaxes(title_text=\"VT per seed\", row=1, col=i+1)\n",
    "            fig.update_yaxes(title_text=\"Frequency\", row=1, col=i+1)\n",
    "\n",
    "        # -- bottom row boxplot --\n",
    "        for sc in scenarios:\n",
    "            fig.add_trace(\n",
    "                go.Box(\n",
    "                    y=box_df[box_df.scenario == sc][\"prop_static\"],\n",
    "                    name=sc,\n",
    "                    boxmean=\"sd\"\n",
    "                ),\n",
    "                row=2, col=1\n",
    "            )\n",
    "\n",
    "        fig.update_layout(\n",
    "            height=700,\n",
    "            width=1200,\n",
    "            title=f\"Instance topology  |  N={n_services}  |  City={city}\",\n",
    "            showlegend=False,\n",
    "            template=\"plotly_white\"\n",
    "        )\n",
    "\n",
    "        fig.show()\n",
    "\n",
    "    # ---- WIDGETS ----\n",
    "    # Default values\n",
    "    default_n = n_services_list[0]\n",
    "    default_city = available_cities(default_n)[0]\n",
    "\n",
    "    # Use interact to automatically re-run draw() on change\n",
    "    interact(\n",
    "        draw,\n",
    "        n_services=Dropdown(options=n_services_list, value=default_n, description=\"N services\"),\n",
    "        city=Dropdown(options=available_cities(default_n), value='ALL', description=\"City\")\n",
    "    )\n",
    "\n",
    "plot_topology_reactive(\n",
    "    results=results,\n",
    "    n_services_list=n_services,\n",
    "    scenarios=scenarios,\n",
    "    seeds=seeds\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754ad3a8",
   "metadata": {},
   "source": [
    "## Detail analysis of scenario/seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464b4391",
   "metadata": {},
   "source": [
    "### Thorough details for a given instance\n",
    "\n",
    "Great, now I want to be able to recover the details of a particular instance. More specifically, I want to be able to select with dropdowns the n_services, the scenario and the seed. For that particular instance, I'd like to be able to visualize:\n",
    "- Number of services\n",
    "- Number of vehicle transportation labors\n",
    "\n",
    "- Proportion of static/dynamic\n",
    "- Number of static VT labors\n",
    "- Number of dynamic VT labors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6740c345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48134568",
   "metadata": {},
   "source": [
    "# Result visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a379e0",
   "metadata": {},
   "source": [
    "## Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82924548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def load_all_results_explicit(\n",
    "    root_dir: str,\n",
    "    n_services_list,\n",
    "    scenarios_list,\n",
    "    seeds_list,\n",
    "    dist_methods_list,\n",
    "    algorithms_list\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean, explicit loader for result files located in:\n",
    "    root/N{n_services}/{scenario}/seed_{seed}/{dist_method}/{algorithm}.pkl\n",
    "\n",
    "    Returns a tidy DataFrame with columns:\n",
    "    [n_services, scenario, seed, dist_method, algorithm, labors_df, moves_df, metadata]\n",
    "    \"\"\"\n",
    "    root = Path(root_dir)\n",
    "    rows = []\n",
    "\n",
    "    for n_services in n_services_list:\n",
    "        n_dir = root / f\"N{n_services}\"\n",
    "\n",
    "        for scenario in scenarios_list:\n",
    "            scenario_dir = n_dir / scenario\n",
    "\n",
    "            for seed in seeds_list:\n",
    "                seed_dir = scenario_dir / f\"seed_{seed}\"\n",
    "\n",
    "                for dist_method in dist_methods_list:\n",
    "                    dist_dir = seed_dir / dist_method\n",
    "\n",
    "                    for algorithm in algorithms_list:\n",
    "                        pkl_path = dist_dir / f\"res_algo_{algorithm}.pkl\"\n",
    "\n",
    "                        if not pkl_path.exists():\n",
    "                            print(f\"⚠ Missing file: {pkl_path}\")\n",
    "                            continue\n",
    "\n",
    "                        # Load pickle\n",
    "                        try:\n",
    "                            with open(pkl_path, \"rb\") as f:\n",
    "                                labors_df, moves_df, metadata = pickle.load(f)\n",
    "                        except Exception as e:\n",
    "                            print(f\"❌ Error loading {pkl_path}: {e}\")\n",
    "                            continue\n",
    "\n",
    "                        rows.append({\n",
    "                            \"n_services\": n_services,\n",
    "                            \"scenario\": scenario,\n",
    "                            \"seed\": seed,\n",
    "                            \"dist_method\": dist_method,\n",
    "                            \"algorithm\": algorithm,\n",
    "                            \"labors_df\": labors_df,\n",
    "                            \"moves_df\": moves_df,\n",
    "                            \"metadata\": metadata,\n",
    "                            \"path\": str(pkl_path)\n",
    "                        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "algorithms_list = ['OFFLINE', 'ONLINE_static', 'INSERT', 'INSERT_BUFFER', 'REACT', 'REACT_BUFFER']\n",
    "\n",
    "results_df = load_all_results_explicit(\n",
    "    root_dir=f'{data_path}/resultados/',\n",
    "    n_services_list=n_services,\n",
    "    scenarios_list=scenarios,\n",
    "    seeds_list=seeds,\n",
    "    dist_methods_list=['haversine'],\n",
    "    algorithms_list=algorithms_list\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df00ba2",
   "metadata": {},
   "source": [
    "## Global results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f9129a",
   "metadata": {},
   "source": [
    "Now I want to step to visualizing the actual results of the algorithms in an instance. To visualize this I want to have a very similar visualization to the one that I had previously for the artificial and real instances (this are simulated instances). The metrics that I want to visualize are pretty much the same. However, the visualization of the results will be ia bit different. The main difference is that for the two previous kinds of instances, I was running a full week. This made that the most natural way of visualizing was a weekly time series and a bar graph to the side with aggregates. Now, there's only one day per run, and there are also scenarios. In that sense, I believe the best way to visualize the results will be with box plots. I'm thinking of having all the results in a single plot. This would mean to have a box plot that has three ticks in the x-axis, one per scenario (this would be kind of groups of box plots). For each group (scenario), have one box plot per algorithm. In that sense, I'd need the boxes of each algorithm in the three groups to be the same color and then a unique legend that explains the colors of the boxplots. Again, I want to be able to select the instance number and the city as well. Also, I want to be able to control with a parameter of the plotting function (not necessarily editable on the dropdown, default False) to save the plots in a given directory.\n",
    "\n",
    "I will provide the plotting logic I'm curently using in the artificial instance results, for reference. Before that, Is the logic and the reasoning of what I just explained clear? Would you like to clarify or for me to further explain anything?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033d8500",
   "metadata": {},
   "source": [
    "Have everything for all the metrics included in the AD_results visualization a boxplot per scenario (showing the seeds within each scenario). This will be per N in a dropdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f01639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00a452fc",
   "metadata": {},
   "source": [
    "## Results per sceneario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b479af7",
   "metadata": {},
   "source": [
    "Have for all the metrics, bar chart that shows the value for each seed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3858bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a46e9d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AlfredEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
