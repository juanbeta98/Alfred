{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "251e34a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from src.data_load import load_tables, load_instance, load_distances\n",
    "from src.metrics import  collect_results_to_df, compute_metrics_with_moves\n",
    "from src.alpha_tuning_utils import compute_baseline_metrics, collect_alpha_metrics, \\\n",
    "    add_aggregated_totals, alphas, iterations_nums, metrics\n",
    "from src.experimentation_config import instance_map, fechas_dict\n",
    "\n",
    "data_path = '../data'\n",
    "\n",
    "instance = 'instAS1'        # Options: ['instAS1', 'instRS1']\n",
    "\n",
    "distance_type = 'osrm'              # Options: ['osrm', 'manhattan']\n",
    "distance_method = 'haversine'      # Options: ['precalced', 'haversine']\n",
    "\n",
    "instance_type = instance_map[instance]\n",
    "fechas = fechas_dict[instance]\n",
    "\n",
    "directorio_df, labors_raw_df, cities_df, duraciones_df, valid_cities = load_tables(data_path, generate_labors=False)\n",
    "labors_real_df = load_instance(data_path, instance, labors_raw_df)\n",
    "dist_dict = load_distances(data_path, 'osrm', instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6395d4",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "This notebook provides an analysis of the experimentation of alpha calibration with the three different objectives for the calibration: \n",
    "\n",
    "- hybrid\n",
    "- extra_time\n",
    "- driver_move_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc56d4a",
   "metadata": {},
   "source": [
    "# Process results data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2c16f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df = compute_baseline_metrics(\n",
    "    data_path=data_path, \n",
    "    instance=instance, \n",
    "    fechas=fechas, \n",
    "    valid_cities=valid_cities, \n",
    "    dist_dict=dist_dict\n",
    ")\n",
    "\n",
    "metrics_df = pd.DataFrame()\n",
    "for metric in metrics:\n",
    "    met_df = collect_alpha_metrics(\n",
    "                                    data_path=data_path,\n",
    "                                    alphas=alphas,\n",
    "                                    instance=instance,\n",
    "                                    iterations_nums=iterations_nums,\n",
    "                                    dist_method='haversine',\n",
    "                                    optimization=metric\n",
    "                                   )\n",
    "    met_df['metric'] = metric\n",
    "    metrics_df = pd.concat([metrics_df, met_df])\n",
    "\n",
    "metrics_df = metrics_df.join(baseline_df.set_index(\"city\"), on=\"city\")\n",
    "metrics_w_totals_df = add_aggregated_totals(metrics_df, group_by=[\"alpha\", \"num_iterations\", 'metric'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68cfd8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "def plot_metrics_vs_alpha(metrics_df):\n",
    "    def _plot(num_iter, city, perf_metric):\n",
    "        # Filter by iteration and city\n",
    "        df = metrics_df[(metrics_df[\"num_iterations\"] == num_iter) & (metrics_df[\"city\"] == city)]\n",
    "        if df.empty:\n",
    "            print(\"⚠️ No data for this selection\")\n",
    "            return\n",
    "\n",
    "        # --- Main line plot: one line per optimization metric ---\n",
    "        fig = px.line(\n",
    "            df,\n",
    "            x=\"alpha\",\n",
    "            y=perf_metric,       # performance metric to visualize\n",
    "            color=\"metric\",      # which optimization was used\n",
    "            title=f\"{perf_metric} vs. Alpha<br>iterations={num_iter}, city={city}\",\n",
    "            markers=True\n",
    "        )\n",
    "\n",
    "        # --- Add baseline line ---\n",
    "        baseline_col = f\"{perf_metric}_baseline\"\n",
    "        if baseline_col in df.columns:\n",
    "            baseline_value = df[baseline_col].iloc[0]  # constant for all alphas\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=df[\"alpha\"].unique(),\n",
    "                    y=[baseline_value] * df[\"alpha\"].nunique(),\n",
    "                    mode=\"lines\",\n",
    "                    line=dict(color=\"orange\", dash=\"dash\"),\n",
    "                    name=\"Baseline\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # --- Layout ---\n",
    "        fig.update_layout(\n",
    "            xaxis_title=\"Alpha\",\n",
    "            yaxis_title=perf_metric,\n",
    "            template=\"plotly_white\",\n",
    "            legend=dict(\n",
    "                orientation=\"h\",\n",
    "                yanchor=\"bottom\",\n",
    "                y=-0.3,\n",
    "                xanchor=\"center\",\n",
    "                x=0.5\n",
    "            )\n",
    "        )\n",
    "\n",
    "        fig.show()\n",
    "\n",
    "    interact(\n",
    "        _plot,\n",
    "        num_iter=widgets.Dropdown(\n",
    "            options=sorted(metrics_df[\"num_iterations\"].unique()),\n",
    "            description=\"Iterations:\"\n",
    "        ),\n",
    "        city=widgets.Dropdown(\n",
    "            options=sorted(metrics_df[\"city\"].unique()),\n",
    "            description=\"City:\"\n",
    "        ),\n",
    "        perf_metric=widgets.Dropdown(\n",
    "            options=[\"vt_labors\", \"driver_extra_time\", \"driver_move_distance\"],\n",
    "            description=\"Metric:\"\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4382a0ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f2d694166754eed91fe3fc3297b8e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Iterations:', options=(np.int64(10), np.int64(25), np.int64(50), n…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metrics_vs_alpha(metrics_w_totals_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411a0835",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AlfredEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
