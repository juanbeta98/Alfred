{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64ad4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('../src')))  # Adjust as needed\n",
    "\n",
    "from distance_utils import distance\n",
    "from data_load import load_tables\n",
    "from filtering import filter_labors_by_date, filter_labors_by_city, filter_labores\n",
    "from metrics import collect_vt_metrics_range, show_day_report_dayonly, compute_indicators\n",
    "from preprocessing import remap_to_base_date, build_services_map_df, process_group\n",
    "from plotting import plot_results\n",
    "from config import *\n",
    "from algorithms import remove_drivers, compute_avg_times, run_iteration_chronological, init_drivers\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc4f9d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grupos creados: [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12], [13, 14, 15]]\n",
      "\n",
      "--- Procesamiento Secuencial ---\n",
      "Procesando grupo: [1, 2, 3]\n",
      "Procesando grupo: [4, 5, 6]\n",
      "Procesando grupo: [7, 8, 9]\n",
      "Procesando grupo: [10, 11, 12]\n",
      "Procesando grupo: [13, 14, 15]\n",
      "Resultados secuenciales: [6, 15, 24, 33, 42]\n",
      "Tiempo secuencial: 5.02s\n",
      "\n",
      "--- Procesamiento Paralelo ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-11:\n",
      "Process SpawnPoolWorker-10:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/juanbeta/micromamba/envs/AlfredEnv/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/juanbeta/micromamba/envs/AlfredEnv/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/juanbeta/micromamba/envs/AlfredEnv/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/juanbeta/micromamba/envs/AlfredEnv/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'procesar_grupo_de_tres' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "  File \"/Users/juanbeta/micromamba/envs/AlfredEnv/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/juanbeta/micromamba/envs/AlfredEnv/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/juanbeta/micromamba/envs/AlfredEnv/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/juanbeta/micromamba/envs/AlfredEnv/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'procesar_grupo_de_tres' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/juanbeta/micromamba/envs/AlfredEnv/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/juanbeta/micromamba/envs/AlfredEnv/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/juanbeta/micromamba/envs/AlfredEnv/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/juanbeta/micromamba/envs/AlfredEnv/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'procesar_grupo_de_tres' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-13:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/juanbeta/micromamba/envs/AlfredEnv/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/juanbeta/micromamba/envs/AlfredEnv/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/juanbeta/micromamba/envs/AlfredEnv/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/juanbeta/micromamba/envs/AlfredEnv/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'procesar_grupo_de_tres' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-14:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/juanbeta/micromamba/envs/AlfredEnv/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/Users/juanbeta/micromamba/envs/AlfredEnv/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/juanbeta/micromamba/envs/AlfredEnv/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/juanbeta/micromamba/envs/AlfredEnv/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'procesar_grupo_de_tres' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-15:\n",
      "Process SpawnPoolWorker-16:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     42\u001b[39m inicio = time.time()\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Pool(processes=\u001b[32m2\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     resultados_paralelo = \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocesar_grupo_de_tres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrupos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m tiempo_paralelo = time.time() - inicio\n\u001b[32m     46\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mResultados paralelos: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresultados_paralelo\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/AlfredEnv/lib/python3.13/multiprocessing/pool.py:367\u001b[39m, in \u001b[36mPool.map\u001b[39m\u001b[34m(self, func, iterable, chunksize)\u001b[39m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    363\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''\u001b[39;00m\n\u001b[32m    364\u001b[39m \u001b[33;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[32m    365\u001b[39m \u001b[33;03m    in a list that is returned.\u001b[39;00m\n\u001b[32m    366\u001b[39m \u001b[33;03m    '''\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/AlfredEnv/lib/python3.13/multiprocessing/pool.py:768\u001b[39m, in \u001b[36mApplyResult.get\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    767\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m768\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    769\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ready():\n\u001b[32m    770\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/AlfredEnv/lib/python3.13/multiprocessing/pool.py:765\u001b[39m, in \u001b[36mApplyResult.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    764\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m765\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_event\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/AlfredEnv/lib/python3.13/threading.py:659\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    657\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m659\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    660\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/AlfredEnv/lib/python3.13/threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    361\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "def procesar_grupo_de_tres(chunk):\n",
    "    \"\"\"Función que procesa un grupo de 3 elementos\"\"\"\n",
    "    print(f\"Procesando grupo: {chunk}\")\n",
    "    # Simulamos algún trabajo pesado\n",
    "    time.sleep(1)\n",
    "    # Devolvemos la suma del grupo\n",
    "    return sum(chunk)\n",
    "\n",
    "def dividir_en_grupos(datos, tamaño_grupo=3):\n",
    "    \"\"\"Divide una lista en grupos del tamaño especificado\"\"\"\n",
    "    grupos = []\n",
    "    for i in range(0, len(datos), tamaño_grupo):\n",
    "        grupo = datos[i:i + tamaño_grupo]\n",
    "        grupos.append(grupo)\n",
    "    return grupos\n",
    "\n",
    "# if _name_ == \"_main_\":\n",
    "# Datos de ejemplo\n",
    "numeros = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "\n",
    "# Dividir en grupos de 3\n",
    "grupos = dividir_en_grupos(numeros, 3)\n",
    "print(f\"Grupos creados: {grupos}\")\n",
    "# Resultado: [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12], [13, 14, 15]]\n",
    "\n",
    "# Procesamiento secuencial (para comparar)\n",
    "print(\"\\n--- Procesamiento Secuencial ---\")\n",
    "inicio = time.time()\n",
    "resultados_secuencial = []\n",
    "for grupo in grupos:\n",
    "    resultado = procesar_grupo_de_tres(grupo)\n",
    "    resultados_secuencial.append(resultado)\n",
    "tiempo_secuencial = time.time() - inicio\n",
    "print(f\"Resultados secuenciales: {resultados_secuencial}\")\n",
    "print(f\"Tiempo secuencial: {tiempo_secuencial:.2f}s\")\n",
    "\n",
    "# Procesamiento paralelo con pool.map\n",
    "print(\"\\n--- Procesamiento Paralelo ---\")\n",
    "inicio = time.time()\n",
    "with Pool(processes=2) as pool:\n",
    "    resultados_paralelo = pool.map(procesar_grupo_de_tres, grupos)\n",
    "tiempo_paralelo = time.time() - inicio\n",
    "print(f\"Resultados paralelos: {resultados_paralelo}\")\n",
    "print(f\"Tiempo paralelo: {tiempo_paralelo:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6444bdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from datetime import timedelta\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# ——————————————————————————\n",
    "# Función maestra por ciudad\n",
    "# ——————————————————————————\n",
    "def run_city_pipeline(city_code, start_date):\n",
    "    \"\"\"\n",
    "    Ejecuta TODO el flujo para una ciudad y fecha dada.\n",
    "    start_date: string o Timestamp, mismo para todas las ciudades.\n",
    "    Devuelve: (city_code, df_cleaned, df_moves)\n",
    "    \"\"\"\n",
    "    # 1. Filtrar por ciudad\n",
    "    df_city = filter_labors_by_city(df_dist, str(city_code))\n",
    "    \n",
    "    # 2. Filtrar por rango de fechas (start_date -> start_date+1)\n",
    "    end_date = pd.to_datetime(start_date) + timedelta(days=1)\n",
    "    df_day = filter_labors_by_date(df_city, start_date=start_date, end_date=end_date)\n",
    "    \n",
    "    # 3. Quitar cancelados y ordenar\n",
    "    df_day = (\n",
    "        df_day.query(\"state_service != 'CANCELED'\")\n",
    "        .sort_values(['service_id', 'labor_start_date'])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # 4. Remapear fechas al día base\n",
    "    base_day = pd.to_datetime(start_date).date()\n",
    "    df_day = remap_to_base_date(\n",
    "        df_day, \n",
    "        ['schedule_date', 'labor_start_date', 'labor_end_date'], \n",
    "        base_day\n",
    "    )\n",
    "\n",
    "    # 5. Construir mapa de servicios\n",
    "    services_map_df = build_services_map_df(df_day)\n",
    "\n",
    "    # 6. Procesar grupos\n",
    "    cleaned = [\n",
    "        process_group(grp, DISTANCE_METHOD, DIST_DICT) \n",
    "        for _, grp in df_day.groupby('service_id', sort=False)\n",
    "    ]\n",
    "    df_cleaned_template = pd.concat([c for c in cleaned if not c.empty], ignore_index=True)\n",
    "    df_cleaned_template = df_cleaned_template.merge(\n",
    "        services_map_df, \n",
    "        on=['service_id', 'labor_id'], \n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # 7. Ejecutar la iteración cronológica\n",
    "    df_cleaned, df_moves = run_iteration_chronological(df_cleaned_template)\n",
    "\n",
    "    # 8. Devolver resultados\n",
    "    return city_code, df_cleaned, df_moves\n",
    "\n",
    "\n",
    "# ——————————————————————————\n",
    "# Configuración previa\n",
    "# ——————————————————————————\n",
    "if __name__ == \"__main__\":\n",
    "    # Pre-cargar globals para todos\n",
    "    with open('distances.pkl', 'rb') as f:\n",
    "        DIST_DICT = pickle.load(f)\n",
    "\n",
    "    df_dist = pd.read_pickle(\"df_dist.pkl\")\n",
    "\n",
    "    # Lista de ciudades\n",
    "    city_list = cities_df['cod_ciudad'].tolist()\n",
    "\n",
    "    # Parámetros de fecha\n",
    "    start_date = \"2023-01-02\"\n",
    "\n",
    "    # Paralelizar\n",
    "    with Pool(processes=4) as pool:  # ajusta procesos según tu CPU\n",
    "        results = pool.starmap(run_city_pipeline, [(c, start_date) for c in city_list])\n",
    "\n",
    "    # Resultados como diccionario\n",
    "    results_by_city = {city: (df_cleaned, df_moves) for city, df_cleaned, df_moves in results}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce507508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AlfredEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
